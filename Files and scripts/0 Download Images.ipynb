{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"0 Download Images.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1OHb7yBe3MfuZILAM0C8MTlIvK9pE5rgR","authorship_tag":"ABX9TyOuHY2mj0JX3gjTxBQrcDd+"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"99tzja_33qoi","colab_type":"code","colab":{}},"source":["import os\n","import codecs\n","import pandas as pd\n","from argparse import ArgumentParser\n","from urllib import request\n","from tqdm import trange\n","from joblib import Parallel, delayed\n","\n","#https://stackoverflow.com/questions/36445193/splitting-one-csv-into-multiple-files-in-python\n","def split(filehandler, delimiter=',', row_limit=20000,\n","          output_name_template='drive/My Drive/Data/book32-listing-split_%s.csv', output_path='.', keep_headers=True):\n","    import csv\n","    reader = csv.reader(filehandler, delimiter=delimiter)\n","    current_piece = 1\n","    current_out_path = os.path.join(\n","        output_path,\n","        output_name_template % current_piece\n","    )\n","    current_out_writer = csv.writer(open(current_out_path, 'w'), delimiter=delimiter)\n","    current_limit = row_limit\n","    if keep_headers:\n","        headers = reader.__next__()\n","        current_out_writer.writerow(headers)\n","    for i, row in enumerate(reader):\n","        if i + 1 > current_limit:\n","            current_piece += 1\n","            current_limit = row_limit * current_piece\n","            current_out_path = os.path.join(\n","                output_path,\n","                output_name_template % current_piece\n","            )\n","            current_out_writer = csv.writer(open(current_out_path, 'w'), delimiter=delimiter)\n","            if keep_headers:\n","                current_out_writer.writerow(headers)\n","        current_out_writer.writerow(row)\n","\n","# Don't run more than once!\n","#split(open('drive/My Drive/Data/book32-listing.csv', mode='r', encoding='utf-8', errors='ignore'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"idsu7Hle1oXu","colab_type":"code","colab":{}},"source":["header_names = ['Amazon ID (ASIN)', 'Filename', 'Image URL', 'Title', 'Author', 'Category ID',\n","                'Category']\n","\n","def download_image(i):\n","    filename = csv.iloc[i]['Filename']\n","    category = csv.iloc[i]['Category']\n","    inner_output_dirpath = os.path.join(\"drive/My Drive/images\", category)\n","    if not os.path.isdir(inner_output_dirpath):\n","        os.mkdir(inner_output_dirpath)\n","    output_filepath = os.path.join(inner_output_dirpath, filename)\n","\n","    url = csv.iloc[i]['Image URL']\n","    if not os.path.isfile(output_filepath):\n","        downloaded_img = request.urlopen(url)\n","        f = open(output_filepath, mode='wb')\n","        f.write(downloaded_img.read())\n","        downloaded_img.close()\n","        f.close()\n","\n","if not os.path.isdir(\"drive/My Drive/images\"):\n","    os.makedirs(\"drive/My Drive/images\")\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Voowqj-3U0U","colab_type":"code","colab":{}},"source":["with codecs.open('drive/My Drive/Data/book32-listing-split_1.csv', mode='r', encoding='utf-8', errors='ignore') as f:\n","    csv = pd.read_csv(f, delimiter=\",\", header=None, names=header_names)\n","\n","print('[Download images into \"{}\"]'.format(\"images\"))\n","\n","Parallel(n_jobs=-1)(delayed(download_image)(i) for i in trange(len(csv)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Z4m27KB5lK7","colab_type":"code","colab":{}},"source":["with codecs.open('drive/My Drive/Data/book32-listing-split_2.csv', mode='r', encoding='utf-8', errors='ignore') as f:\n","    csv = pd.read_csv(f, delimiter=\",\", header=None, names=header_names)\n","\n","print('[Download images into \"{}\"]'.format(\"images\"))\n","\n","Parallel(n_jobs=-1)(delayed(download_image)(i) for i in trange(len(csv)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tUZJ47fy5luS","colab_type":"code","colab":{}},"source":["with codecs.open('drive/My Drive/Data/book32-listing-split_3.csv', mode='r', encoding='utf-8', errors='ignore') as f:\n","    csv = pd.read_csv(f, delimiter=\",\", header=None, names=header_names)\n","\n","print('[Download images into \"{}\"]'.format(\"images\"))\n","\n","Parallel(n_jobs=-1)(delayed(download_image)(i) for i in trange(len(csv)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DFm2vu9w5mSt","colab_type":"code","colab":{}},"source":["with codecs.open('drive/My Drive/Data/book32-listing-split_4.csv', mode='r', encoding='utf-8', errors='ignore') as f:\n","    csv = pd.read_csv(f, delimiter=\",\", header=None, names=header_names)\n","\n","print('[Download images into \"{}\"]'.format(\"images\"))\n","\n","Parallel(n_jobs=-1)(delayed(download_image)(i) for i in trange(len(csv)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H6-7QfKL5mpj","colab_type":"code","colab":{}},"source":["with codecs.open('drive/My Drive/Data/book32-listing-split_5.csv', mode='r', encoding='utf-8', errors='ignore') as f:\n","    csv = pd.read_csv(f, delimiter=\",\", header=None, names=header_names)\n","\n","print('[Download images into \"{}\"]'.format(\"images\"))\n","\n","Parallel(n_jobs=-1)(delayed(download_image)(i) for i in trange(len(csv)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4yixbbi1XsN4","colab_type":"code","colab":{}},"source":["with codecs.open('drive/My Drive/Data/book32-listing-split_6.csv', mode='r', encoding='utf-8', errors='ignore') as f:\n","    csv = pd.read_csv(f, delimiter=\",\", header=None, names=header_names)\n","\n","print('[Download images into \"{}\"]'.format(\"images\"))\n","\n","Parallel(n_jobs=-1)(delayed(download_image)(i) for i in trange(len(csv)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1TjgCodqXvY8","colab_type":"code","colab":{}},"source":["with codecs.open('drive/My Drive/Data/book32-listing-split_7.csv', mode='r', encoding='utf-8', errors='ignore') as f:\n","    csv = pd.read_csv(f, delimiter=\",\", header=None, names=header_names)\n","\n","print('[Download images into \"{}\"]'.format(\"images\"))\n","\n","Parallel(n_jobs=-1)(delayed(download_image)(i) for i in trange(len(csv)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n6zJXJfUXwiF","colab_type":"code","colab":{}},"source":["with codecs.open('drive/My Drive/Data/book32-listing-split_8.csv', mode='r', encoding='utf-8', errors='ignore') as f:\n","    csv = pd.read_csv(f, delimiter=\",\", header=None, names=header_names)\n","\n","print('[Download images into \"{}\"]'.format(\"images\"))\n","\n","Parallel(n_jobs=-1)(delayed(download_image)(i) for i in trange(len(csv)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bP5rQlvfXzA6","colab_type":"code","colab":{}},"source":["with codecs.open('drive/My Drive/Data/book32-listing-split_9.csv', mode='r', encoding='utf-8', errors='ignore') as f:\n","    csv = pd.read_csv(f, delimiter=\",\", header=None, names=header_names)\n","\n","print('[Download images into \"{}\"]'.format(\"images\"))\n","\n","Parallel(n_jobs=-1)(delayed(download_image)(i) for i in trange(len(csv)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zZmG-6_8X0OX","colab_type":"code","colab":{}},"source":["with codecs.open('drive/My Drive/Data/book32-listing-split_10.csv', mode='r', encoding='utf-8', errors='ignore') as f:\n","    csv = pd.read_csv(f, delimiter=\",\", header=None, names=header_names)\n","\n","print('[Download images into \"{}\"]'.format(\"images\"))\n","\n","Parallel(n_jobs=-1)(delayed(download_image)(i) for i in trange(len(csv)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mpbWz-LXX1v-","colab_type":"code","colab":{}},"source":["with codecs.open('drive/My Drive/Data/book32-listing-split_11.csv', mode='r', encoding='utf-8', errors='ignore') as f:\n","    csv = pd.read_csv(f, delimiter=\",\", header=None, names=header_names)\n","\n","print('[Download images into \"{}\"]'.format(\"images\"))\n","\n","Parallel(n_jobs=-1)(delayed(download_image)(i) for i in trange(len(csv)))"],"execution_count":0,"outputs":[]}]}