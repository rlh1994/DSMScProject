{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5 Evaluate Models.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_J1kcdqtCbi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "74dbefbe-df0f-488f-da5b-38f026c66d13"
      },
      "source": [
        "!pip install image-classifiers==1.0.0b1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting image-classifiers==1.0.0b1\n",
            "  Downloading https://files.pythonhosted.org/packages/d0/15/c51837c7009063ab9e4d3654eb32a92838fe515023cc7862e06857c9d19b/image_classifiers-1.0.0b1.tar.gz\n",
            "Building wheels for collected packages: image-classifiers\n",
            "  Building wheel for image-classifiers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for image-classifiers: filename=image_classifiers-1.0.0b1-cp36-none-any.whl size=19956 sha256=4d19cda30fd16eee849ca91e41142ab38cc66763bb706fafe4381102c3a0cb25\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/22/b6/715c09496e4a64024b00a695e07a2b5804286f4840852fbcd3\n",
            "Successfully built image-classifiers\n",
            "Installing collected packages: image-classifiers\n",
            "Successfully installed image-classifiers-1.0.0b1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dY37vzOLtHRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Library imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "import re\n",
        "from classification_models.tfkeras import Classifiers"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsKSoyfdvOr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 30\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npmSCgQsvndy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://medium.com/@mrgarg.rajat/training-on-large-datasets-that-dont-fit-in-memory-in-keras-60a974785d71\n",
        "\n",
        "\n",
        "class My_Custom_Generator(tf.keras.utils.Sequence) :\n",
        "  \n",
        "  def __init__(self, image_filenames, labels, batch_size, IMG_HEIGHT, IMG_WIDTH) :\n",
        "    self.image_filenames = image_filenames\n",
        "    self.labels = labels\n",
        "    self.batch_size = batch_size\n",
        "    self.IMG_HEIGHT = IMG_HEIGHT\n",
        "    self.IMG_WIDTH = IMG_WIDTH\n",
        "    \n",
        "    \n",
        "  def __len__(self) :\n",
        "    return (np.ceil(len(self.image_filenames) / float(self.batch_size))).astype(np.int)\n",
        "  \n",
        "  \n",
        "  def __getitem__(self, idx) :\n",
        "    batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n",
        "    batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n",
        "    \n",
        "    return np.array([\n",
        "            np.resize(imread(str(file_name)), (self.IMG_HEIGHT, self.IMG_WIDTH, 3))\n",
        "               for file_name in batch_x])/255.0, np.array(batch_y)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZFWBu0uteU7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def top_n_accuracy(preds, truths, n, model, sparse = True):\n",
        "    \"\"\" Thank you stackoverflow https://stackoverflow.com/questions/32461246/how-to-get-top-3-or-top-n-predictions-using-sklearns-sgdclassifier/48572046\"\"\"\n",
        "    best_n = np.argsort(preds, axis=1)[:,-n:]\n",
        "    if sparse: \n",
        "        ts = truths\n",
        "    else:\n",
        "        ts = np.argmax(truths, axis=1)\n",
        "    successes = 0\n",
        "    for i in range(ts.shape[0]):\n",
        "        if ts[i] in best_n[i,:]:\n",
        "            successes += 1\n",
        "    return {'Model': model, 'N': n, 'Class': 'Total', 'Result': float(successes)/ts.shape[0]}\n",
        "\n",
        "def top_n_recall_per_class(preds, truths, n, classes, model, sparse = True):\n",
        "    n_classes = len(classes)\n",
        "    best_n = np.argsort(preds, axis=1)[:,-n:]\n",
        "    if sparse: \n",
        "        ts = truths\n",
        "    else:\n",
        "        ts = np.argmax(truths, axis=1)\n",
        "    successes = [0]*n_classes\n",
        "    class_count = [0]*n_classes\n",
        "    for i in range(ts.shape[0]):\n",
        "        class_count[ts[i]] += 1\n",
        "        if ts[i] in best_n[i,:]:\n",
        "            successes[ts[i]] += 1\n",
        "    return [{'Model': model, 'N': n, 'Class': k, 'Result': v} for k,v in zip(classes, [float(i)/float(j) for i, j in zip(successes, class_count)])]\n",
        "    #return {k:v for k, v in zip(classes, [float(i)/float(j) for i, j in zip(successes, class_count)])}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tTTSufptkPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_test_data():\n",
        "    with open('/content/drive/My Drive/Data/final-book30-labels-test.csv', mode='r', encoding='utf-8', errors='ignore') as f:\n",
        "        test_labels = pd.read_csv(f, delimiter=\",\", header=None, names=['record', 'Filename', 'Category ID'])\n",
        "\n",
        "    test_labels = test_labels.assign(Full_Filename = '/content/padded/'+ test_labels[\"Filename\"])\n",
        "\n",
        "    print('Loading data')\n",
        "     # Load actual data\n",
        "    zip_path = '/content/drive/My Drive/images/Test/padded.zip'\n",
        "    !cp \"{zip_path}\" .\n",
        "    !unzip -q \"padded.zip\" \n",
        "    !rm \"padded.zip\" \n",
        "\n",
        "    return test_labels\n",
        "\n",
        "def test_data_pred(base_model, IMG_HEIGHT, IMG_WIDTH, folder, test_labels):\n",
        "    my_test_batch_generator = My_Custom_Generator(test_labels[\"Full_Filename\"], test_labels[\"Category ID\"], BATCH_SIZE, IMG_HEIGHT, IMG_WIDTH)\n",
        "    print('Loading model')\n",
        "\n",
        "    base_model.trainable = False\n",
        "\n",
        "    model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(30, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='Adam',\n",
        "              loss='SparseCategoricalCrossentropy',\n",
        "              metrics=['accuracy', tf.keras.metrics.SparseTopKCategoricalAccuracy(3)])\n",
        "    \n",
        "    files = os.listdir(f'/content/drive/My Drive/Models/{folder}/')\n",
        "    pat = re.compile(f'^.*\\.h5$')\n",
        "    files_cut = [i for i in files if pat.match(i) ]\n",
        "    model_weights = max(files_cut)\n",
        "\n",
        "    model.load_weights(f'/content/drive/My Drive/Models/{folder}/{model_weights}')\n",
        "\n",
        "    print('Making predition')\n",
        "\n",
        "    y_pred = model.predict(my_test_batch_generator, steps = int(len(test_labels) // BATCH_SIZE), verbose = 1)\n",
        "    \n",
        "\n",
        "    return y_pred, test_labels[\"Category ID\"]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibgB_oIAvJ8s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d0590796-a0bc-4177-8eee-c202be0cdd11"
      },
      "source": [
        "test_labels = load_test_data()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9DsqXY6vBAl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "b3ee8921-0ccf-4666-fc69-20bc4e6a9a37"
      },
      "source": [
        "## MobileNetV2\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3),\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n",
        "mnet_preds, test_actual = test_data_pred(base_model, 224, 224, 'mobilenet', test_labels)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n",
            "Loading model\n",
            "Making predition\n",
            "190/190 [==============================] - 19s 99ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYuqHjWN70QS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "655f123b-a21b-44d4-9937-f4e6363cd117"
      },
      "source": [
        "## InceptionResnetV2\n",
        "base_model = tf.keras.applications.InceptionResNetV2(input_shape=(299, 299, 3),\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n",
        "incep_preds, test_actual = test_data_pred(base_model, 299, 299, 'inception_resnetv2', test_labels)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "219062272/219055592 [==============================] - 2s 0us/step\n",
            "Loading model\n",
            "Making predition\n",
            "190/190 [==============================] - 34s 180ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sr9EQhKh71Tx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "1e069b25-f73c-4920-ae09-50e0af4c4773"
      },
      "source": [
        "# Resnext, has to come from anotehr package\n",
        "resnext50, preprocess_input = Classifiers.get('resnext50')\n",
        "base_model = resnext50((224, 224, 3), weights='imagenet', include_top = False)\n",
        "\n",
        "resnext_preds, test_actual = test_data_pred(base_model, 224, 224, 'resnext', test_labels)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/qubvel/classification_models/releases/download/0.0.1/resnext50_imagenet_1000_no_top.h5\n",
            "94429184/94428600 [==============================] - 3s 0us/step\n",
            "Loading model\n",
            "Making predition\n",
            "190/190 [==============================] - 23s 121ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9DWFI9H8jZt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnet_df = pd.DataFrame(mnet_preds)\n",
        "mnet_df = mnet_df.assign(Filename = test_labels['Filename'])\n",
        "mnet_df.to_csv('/content/drive/My Drive/Data/Predictions/mobilenetV2_preds.csv', header = True, index = False)\n",
        "\n",
        "incep_df = pd.DataFrame(incep_preds)\n",
        "incep_df = incep_df.assign(Filename = test_labels['Filename'])\n",
        "incep_df.to_csv('/content/drive/My Drive/Data/Predictions/InceptionResnetV2_preds.csv', header = True, index = False)\n",
        "\n",
        "resnext_df = pd.DataFrame(resnext_preds)\n",
        "resnext_df = resnext_df.assign(Filename = test_labels['Filename'])\n",
        "resnext_df.to_csv('/content/drive/My Drive/Data/Predictions/Resnext_preds.csv', header = True, index = False)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSttxRIFyZBk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = []\n",
        "for i in range(1, 6):\n",
        "    results.extend([top_n_accuracy(mnet_preds, test_actual, i, 'MobileNetV2')])\n",
        "    results.extend(top_n_recall_per_class(mnet_preds, test_actual, i, range(30), 'MobileNetV2'))\n",
        "    results.extend([top_n_accuracy(incep_preds, test_actual, i, 'InceptionResnetV2')])\n",
        "    results.extend(top_n_recall_per_class(incep_preds, test_actual, i, range(30), 'InceptionResnetV2'))\n",
        "    results.extend([top_n_accuracy(resnext_preds, test_actual, i, 'ResneXt50')])\n",
        "    results.extend(top_n_recall_per_class(resnext_preds, test_actual, i, range(30), 'ResneXt50'))"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhqdCNNQ1sTw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.concat([pd.Series(d) for d in results], axis=1).fillna(0).T"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7-qcmXS1yLJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv('/content/drive/My Drive/Data/Predictions/all_top_n_results.csv', header = True, index = False)"
      ],
      "execution_count": 39,
      "outputs": []
    }
  ]
}