{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3 Identify Best Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load libraries and define functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgqIwdyqHqyc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d9b9ef22-abf3-4e3c-927d-e1744a79b300"
      },
      "source": [
        "# Library imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "from sklearn.metrics import accuracy_score\n",
        "import re"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxkMWUAEQYss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model/training variables. batch size must be divisor of number of training, validation, and test records.\n",
        "BATCH_SIZE = 30\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8clK1LDew74c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://medium.com/@mrgarg.rajat/training-on-large-datasets-that-dont-fit-in-memory-in-keras-60a974785d71\n",
        "# This generator has to be used because the dataset is too large to keep in memory so we have to load it in in batches.\n",
        "\n",
        "class My_Custom_Generator(tf.keras.utils.Sequence) :\n",
        "  \n",
        "  def __init__(self, image_filenames, labels, batch_size, IMG_HEIGHT, IMG_WIDTH) :\n",
        "    self.image_filenames = image_filenames\n",
        "    self.labels = labels\n",
        "    self.batch_size = batch_size\n",
        "    self.IMG_HEIGHT = IMG_HEIGHT\n",
        "    self.IMG_WIDTH = IMG_WIDTH\n",
        "    \n",
        "    \n",
        "  def __len__(self) :\n",
        "    return (np.ceil(len(self.image_filenames) / float(self.batch_size))).astype(np.int)\n",
        "  \n",
        "  \n",
        "  def __getitem__(self, idx) :\n",
        "    batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n",
        "    batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n",
        "    \n",
        "    return np.array([\n",
        "            np.resize(imread(str(file_name)), (self.IMG_HEIGHT, self.IMG_WIDTH, 3))\n",
        "               for file_name in batch_x])/255.0, np.array(batch_y)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luXB5RSnwOzP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prep_data_and_model(dataset, skip_load = False):\n",
        "    \"\"\"\n",
        "    Function to load all the relevant data, train the model with early stopping, saving best validation accuracy snapshots, and \n",
        "        save training results to a file for later visualisation. \n",
        "    arg:\n",
        "        dataset - name of the dataset files to work from\n",
        "        skip_load - should the load from drive into colab be skipped\n",
        "    \"\"\"\n",
        "    print('Loading Data details')\n",
        "    # Prep datasets\n",
        "    with open('/content/drive/My Drive/Data/final-book30-labels-train.csv', mode='r', encoding='utf-8', errors='ignore') as f:\n",
        "        train_labels = pd.read_csv(f, delimiter=\",\", header=None, names=['record', 'Filename', 'Category ID'])\n",
        "\n",
        "    with open('/content/drive/My Drive/Data/final-book30-labels-valid.csv', mode='r', encoding='utf-8', errors='ignore') as f:\n",
        "        valid_labels = pd.read_csv(f, delimiter=\",\", header=None, names=['record', 'Filename', 'Category ID'])\n",
        "\n",
        "    train_labels = train_labels.assign(Full_Filename = f'/content/{dataset}/'+ train_labels[\"Filename\"])\n",
        "    valid_labels = valid_labels.assign(Full_Filename = f'/content/valid_{dataset}/{dataset}/'+ valid_labels[\"Filename\"])\n",
        "\n",
        "    print('Loading data')\n",
        "    if not skip_load:\n",
        "        # Load actual data\n",
        "        zip_path = f'/content/drive/My Drive/images/Train/{dataset}.zip'\n",
        "        !cp \"{zip_path}\" .\n",
        "        !unzip -q \"{dataset}.zip\" \n",
        "        !rm \"{dataset}.zip\" \n",
        "\n",
        "        zip_path = f'/content/drive/My Drive/images/Valid/{dataset}.zip'\n",
        "        !cp \"{zip_path}\" .\n",
        "        !unzip -q \"{dataset}.zip\"  -d \"valid_{dataset}\" \n",
        "        !rm \"{dataset}.zip\" \n",
        "\n",
        "    print('Prepping model')\n",
        "    my_training_batch_generator = My_Custom_Generator(train_labels[\"Full_Filename\"], train_labels[\"Category ID\"], BATCH_SIZE, IMG_HEIGHT, IMG_WIDTH)\n",
        "    my_validation_batch_generator = My_Custom_Generator(valid_labels[\"Full_Filename\"], valid_labels[\"Category ID\"], BATCH_SIZE, IMG_HEIGHT, IMG_WIDTH)\n",
        "\n",
        "    base_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3),\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n",
        "\n",
        "    base_model.trainable = False\n",
        "\n",
        "    model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(30, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='Adam',\n",
        "              loss='SparseCategoricalCrossentropy',\n",
        "              metrics=['accuracy', tf.keras.metrics.SparseTopKCategoricalAccuracy(3)])\n",
        "    \n",
        "      #early stopping and checkpoints\n",
        "    es = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', verbose=1, patience=15)\n",
        "    mc = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/My Drive/Models/data_explore/{dataset}' + '_{epoch:02d}.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True, save_weights_only=True)\n",
        "    cl = tf.keras.callbacks.CSVLogger(f\"/content/drive/My Drive/Models/data_explore/{dataset}_model_history_log.csv\", append = True)\n",
        "\n",
        "    print('Training model')\n",
        "    history = model.fit_generator(generator=my_training_batch_generator, \n",
        "                              validation_data = my_validation_batch_generator,\n",
        "                              steps_per_epoch = int(len(train_labels) // BATCH_SIZE),\n",
        "                              validation_steps = int(5130 // BATCH_SIZE),\n",
        "                              epochs = 30,\n",
        "                              verbose = 1,\n",
        "                              callbacks = [es, mc, cl])\n",
        "    \n",
        "    return history\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ye5mmy8zk2Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0ab21730-5806-4630-ab03-9779ed14caf8"
      },
      "source": [
        "prep_data_and_model('padded', True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Data details\n",
            "Loading data\n",
            "Prepping model\n",
            "Training model\n",
            "Epoch 1/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 3.2147 - accuracy: 0.1188 - sparse_top_k_categorical_accuracy: 0.2564\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.14113, saving model to /content/drive/My Drive/Models/data_explore/padded_01.h5\n",
            "1539/1539 [==============================] - 202s 131ms/step - loss: 3.2147 - accuracy: 0.1188 - sparse_top_k_categorical_accuracy: 0.2564 - val_loss: 3.1468 - val_accuracy: 0.1411 - val_sparse_top_k_categorical_accuracy: 0.2922\n",
            "Epoch 2/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 3.0491 - accuracy: 0.1575 - sparse_top_k_categorical_accuracy: 0.3187\n",
            "Epoch 00002: val_accuracy improved from 0.14113 to 0.14172, saving model to /content/drive/My Drive/Models/data_explore/padded_02.h5\n",
            "1539/1539 [==============================] - 158s 103ms/step - loss: 3.0491 - accuracy: 0.1575 - sparse_top_k_categorical_accuracy: 0.3187 - val_loss: 3.2435 - val_accuracy: 0.1417 - val_sparse_top_k_categorical_accuracy: 0.2795\n",
            "Epoch 3/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.9820 - accuracy: 0.1751 - sparse_top_k_categorical_accuracy: 0.3421\n",
            "Epoch 00003: val_accuracy improved from 0.14172 to 0.15712, saving model to /content/drive/My Drive/Models/data_explore/padded_03.h5\n",
            "1539/1539 [==============================] - 158s 103ms/step - loss: 2.9820 - accuracy: 0.1751 - sparse_top_k_categorical_accuracy: 0.3421 - val_loss: 3.0864 - val_accuracy: 0.1571 - val_sparse_top_k_categorical_accuracy: 0.3129\n",
            "Epoch 4/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.9219 - accuracy: 0.1873 - sparse_top_k_categorical_accuracy: 0.3637\n",
            "Epoch 00004: val_accuracy did not improve from 0.15712\n",
            "1539/1539 [==============================] - 158s 103ms/step - loss: 2.9219 - accuracy: 0.1873 - sparse_top_k_categorical_accuracy: 0.3637 - val_loss: 3.1091 - val_accuracy: 0.1559 - val_sparse_top_k_categorical_accuracy: 0.3140\n",
            "Epoch 5/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.8901 - accuracy: 0.1951 - sparse_top_k_categorical_accuracy: 0.3754\n",
            "Epoch 00005: val_accuracy improved from 0.15712 to 0.17076, saving model to /content/drive/My Drive/Models/data_explore/padded_05.h5\n",
            "1539/1539 [==============================] - 157s 102ms/step - loss: 2.8901 - accuracy: 0.1951 - sparse_top_k_categorical_accuracy: 0.3754 - val_loss: 3.0868 - val_accuracy: 0.1708 - val_sparse_top_k_categorical_accuracy: 0.3172\n",
            "Epoch 6/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.8639 - accuracy: 0.1998 - sparse_top_k_categorical_accuracy: 0.3827\n",
            "Epoch 00006: val_accuracy did not improve from 0.17076\n",
            "1539/1539 [==============================] - 158s 102ms/step - loss: 2.8639 - accuracy: 0.1998 - sparse_top_k_categorical_accuracy: 0.3827 - val_loss: 3.0839 - val_accuracy: 0.1571 - val_sparse_top_k_categorical_accuracy: 0.3175\n",
            "Epoch 7/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.8399 - accuracy: 0.2084 - sparse_top_k_categorical_accuracy: 0.3941\n",
            "Epoch 00007: val_accuracy did not improve from 0.17076\n",
            "1539/1539 [==============================] - 158s 102ms/step - loss: 2.8399 - accuracy: 0.2084 - sparse_top_k_categorical_accuracy: 0.3941 - val_loss: 3.1122 - val_accuracy: 0.1641 - val_sparse_top_k_categorical_accuracy: 0.3199\n",
            "Epoch 8/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.8226 - accuracy: 0.2087 - sparse_top_k_categorical_accuracy: 0.3981\n",
            "Epoch 00008: val_accuracy improved from 0.17076 to 0.17407, saving model to /content/drive/My Drive/Models/data_explore/padded_08.h5\n",
            "1539/1539 [==============================] - 158s 103ms/step - loss: 2.8226 - accuracy: 0.2087 - sparse_top_k_categorical_accuracy: 0.3981 - val_loss: 3.0662 - val_accuracy: 0.1741 - val_sparse_top_k_categorical_accuracy: 0.3277\n",
            "Epoch 9/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.8049 - accuracy: 0.2144 - sparse_top_k_categorical_accuracy: 0.4067\n",
            "Epoch 00009: val_accuracy did not improve from 0.17407\n",
            "1539/1539 [==============================] - 157s 102ms/step - loss: 2.8049 - accuracy: 0.2144 - sparse_top_k_categorical_accuracy: 0.4067 - val_loss: 3.1121 - val_accuracy: 0.1719 - val_sparse_top_k_categorical_accuracy: 0.3144\n",
            "Epoch 10/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.7816 - accuracy: 0.2204 - sparse_top_k_categorical_accuracy: 0.4140\n",
            "Epoch 00010: val_accuracy did not improve from 0.17407\n",
            "1539/1539 [==============================] - 158s 103ms/step - loss: 2.7816 - accuracy: 0.2204 - sparse_top_k_categorical_accuracy: 0.4140 - val_loss: 3.1199 - val_accuracy: 0.1620 - val_sparse_top_k_categorical_accuracy: 0.3209\n",
            "Epoch 11/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.7698 - accuracy: 0.2220 - sparse_top_k_categorical_accuracy: 0.4156\n",
            "Epoch 00011: val_accuracy did not improve from 0.17407\n",
            "1539/1539 [==============================] - 157s 102ms/step - loss: 2.7698 - accuracy: 0.2220 - sparse_top_k_categorical_accuracy: 0.4156 - val_loss: 3.1394 - val_accuracy: 0.1561 - val_sparse_top_k_categorical_accuracy: 0.3152\n",
            "Epoch 12/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.7633 - accuracy: 0.2244 - sparse_top_k_categorical_accuracy: 0.4190\n",
            "Epoch 00012: val_accuracy did not improve from 0.17407\n",
            "1539/1539 [==============================] - 158s 103ms/step - loss: 2.7633 - accuracy: 0.2244 - sparse_top_k_categorical_accuracy: 0.4190 - val_loss: 3.1783 - val_accuracy: 0.1544 - val_sparse_top_k_categorical_accuracy: 0.3068\n",
            "Epoch 13/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.7423 - accuracy: 0.2282 - sparse_top_k_categorical_accuracy: 0.4254\n",
            "Epoch 00013: val_accuracy did not improve from 0.17407\n",
            "1539/1539 [==============================] - 158s 102ms/step - loss: 2.7423 - accuracy: 0.2282 - sparse_top_k_categorical_accuracy: 0.4254 - val_loss: 3.1486 - val_accuracy: 0.1602 - val_sparse_top_k_categorical_accuracy: 0.3152\n",
            "Epoch 14/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.7424 - accuracy: 0.2308 - sparse_top_k_categorical_accuracy: 0.4259\n",
            "Epoch 00014: val_accuracy did not improve from 0.17407\n",
            "1539/1539 [==============================] - 159s 103ms/step - loss: 2.7424 - accuracy: 0.2308 - sparse_top_k_categorical_accuracy: 0.4259 - val_loss: 3.1363 - val_accuracy: 0.1696 - val_sparse_top_k_categorical_accuracy: 0.3197\n",
            "Epoch 15/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.7217 - accuracy: 0.2344 - sparse_top_k_categorical_accuracy: 0.4323\n",
            "Epoch 00015: val_accuracy did not improve from 0.17407\n",
            "1539/1539 [==============================] - 158s 103ms/step - loss: 2.7217 - accuracy: 0.2344 - sparse_top_k_categorical_accuracy: 0.4323 - val_loss: 3.1922 - val_accuracy: 0.1476 - val_sparse_top_k_categorical_accuracy: 0.3146\n",
            "Epoch 16/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.7199 - accuracy: 0.2346 - sparse_top_k_categorical_accuracy: 0.4337\n",
            "Epoch 00016: val_accuracy did not improve from 0.17407\n",
            "1539/1539 [==============================] - 159s 103ms/step - loss: 2.7199 - accuracy: 0.2346 - sparse_top_k_categorical_accuracy: 0.4337 - val_loss: 3.1826 - val_accuracy: 0.1628 - val_sparse_top_k_categorical_accuracy: 0.3121\n",
            "Epoch 17/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.7146 - accuracy: 0.2372 - sparse_top_k_categorical_accuracy: 0.4347\n",
            "Epoch 00017: val_accuracy did not improve from 0.17407\n",
            "1539/1539 [==============================] - 159s 103ms/step - loss: 2.7146 - accuracy: 0.2372 - sparse_top_k_categorical_accuracy: 0.4347 - val_loss: 3.1680 - val_accuracy: 0.1608 - val_sparse_top_k_categorical_accuracy: 0.3133\n",
            "Epoch 18/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.7124 - accuracy: 0.2366 - sparse_top_k_categorical_accuracy: 0.4338\n",
            "Epoch 00018: val_accuracy did not improve from 0.17407\n",
            "1539/1539 [==============================] - 159s 103ms/step - loss: 2.7124 - accuracy: 0.2366 - sparse_top_k_categorical_accuracy: 0.4338 - val_loss: 3.2131 - val_accuracy: 0.1513 - val_sparse_top_k_categorical_accuracy: 0.3047\n",
            "Epoch 19/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.7001 - accuracy: 0.2408 - sparse_top_k_categorical_accuracy: 0.4398\n",
            "Epoch 00019: val_accuracy did not improve from 0.17407\n",
            "1539/1539 [==============================] - 159s 103ms/step - loss: 2.7001 - accuracy: 0.2408 - sparse_top_k_categorical_accuracy: 0.4398 - val_loss: 3.2396 - val_accuracy: 0.1522 - val_sparse_top_k_categorical_accuracy: 0.3019\n",
            "Epoch 20/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.6989 - accuracy: 0.2417 - sparse_top_k_categorical_accuracy: 0.4423\n",
            "Epoch 00020: val_accuracy did not improve from 0.17407\n",
            "1539/1539 [==============================] - 159s 103ms/step - loss: 2.6989 - accuracy: 0.2417 - sparse_top_k_categorical_accuracy: 0.4423 - val_loss: 3.2022 - val_accuracy: 0.1583 - val_sparse_top_k_categorical_accuracy: 0.3162\n",
            "Epoch 21/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.6893 - accuracy: 0.2437 - sparse_top_k_categorical_accuracy: 0.4467\n",
            "Epoch 00021: val_accuracy did not improve from 0.17407\n",
            "1539/1539 [==============================] - 159s 103ms/step - loss: 2.6893 - accuracy: 0.2437 - sparse_top_k_categorical_accuracy: 0.4467 - val_loss: 3.2928 - val_accuracy: 0.1368 - val_sparse_top_k_categorical_accuracy: 0.2916\n",
            "Epoch 22/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.6846 - accuracy: 0.2449 - sparse_top_k_categorical_accuracy: 0.4471\n",
            "Epoch 00022: val_accuracy did not improve from 0.17407\n",
            "1539/1539 [==============================] - 159s 103ms/step - loss: 2.6846 - accuracy: 0.2449 - sparse_top_k_categorical_accuracy: 0.4471 - val_loss: 3.2209 - val_accuracy: 0.1575 - val_sparse_top_k_categorical_accuracy: 0.3125\n",
            "Epoch 23/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.6831 - accuracy: 0.2446 - sparse_top_k_categorical_accuracy: 0.4468\n",
            "Epoch 00023: val_accuracy did not improve from 0.17407\n",
            "1539/1539 [==============================] - 155s 100ms/step - loss: 2.6831 - accuracy: 0.2446 - sparse_top_k_categorical_accuracy: 0.4468 - val_loss: 3.2007 - val_accuracy: 0.1673 - val_sparse_top_k_categorical_accuracy: 0.3175\n",
            "Epoch 00023: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0f2c6bfcc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EJ-4r8tWPbq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r padded\n",
        "!rm -r valid_padded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "784ZLLZ7WIoA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "11713375-4f83-4887-c134-c7515ed37d39"
      },
      "source": [
        "prep_data_and_model('noprep')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Data details\n",
            "Loading data\n",
            "Prepping model\n",
            "Training model\n",
            "Epoch 1/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 3.2778 - accuracy: 0.1094 - sparse_top_k_categorical_accuracy: 0.2478\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.13080, saving model to /content/drive/My Drive/Models/data_explore/noprep_01.h5\n",
            "1539/1539 [==============================] - 164s 106ms/step - loss: 3.2778 - accuracy: 0.1094 - sparse_top_k_categorical_accuracy: 0.2478 - val_loss: 3.2285 - val_accuracy: 0.1308 - val_sparse_top_k_categorical_accuracy: 0.2758\n",
            "Epoch 2/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 3.0931 - accuracy: 0.1498 - sparse_top_k_categorical_accuracy: 0.3083\n",
            "Epoch 00002: val_accuracy improved from 0.13080 to 0.14191, saving model to /content/drive/My Drive/Models/data_explore/noprep_02.h5\n",
            "1539/1539 [==============================] - 163s 106ms/step - loss: 3.0931 - accuracy: 0.1498 - sparse_top_k_categorical_accuracy: 0.3083 - val_loss: 3.1452 - val_accuracy: 0.1419 - val_sparse_top_k_categorical_accuracy: 0.2924\n",
            "Epoch 3/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 3.0136 - accuracy: 0.1678 - sparse_top_k_categorical_accuracy: 0.3374\n",
            "Epoch 00003: val_accuracy improved from 0.14191 to 0.14444, saving model to /content/drive/My Drive/Models/data_explore/noprep_03.h5\n",
            "1539/1539 [==============================] - 162s 105ms/step - loss: 3.0136 - accuracy: 0.1678 - sparse_top_k_categorical_accuracy: 0.3374 - val_loss: 3.1756 - val_accuracy: 0.1444 - val_sparse_top_k_categorical_accuracy: 0.2959\n",
            "Epoch 4/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.9588 - accuracy: 0.1828 - sparse_top_k_categorical_accuracy: 0.3559\n",
            "Epoch 00004: val_accuracy did not improve from 0.14444\n",
            "1539/1539 [==============================] - 162s 106ms/step - loss: 2.9588 - accuracy: 0.1828 - sparse_top_k_categorical_accuracy: 0.3559 - val_loss: 3.1712 - val_accuracy: 0.1409 - val_sparse_top_k_categorical_accuracy: 0.2957\n",
            "Epoch 5/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.9173 - accuracy: 0.1921 - sparse_top_k_categorical_accuracy: 0.3737\n",
            "Epoch 00005: val_accuracy did not improve from 0.14444\n",
            "1539/1539 [==============================] - 167s 108ms/step - loss: 2.9173 - accuracy: 0.1921 - sparse_top_k_categorical_accuracy: 0.3737 - val_loss: 3.2594 - val_accuracy: 0.1314 - val_sparse_top_k_categorical_accuracy: 0.2733\n",
            "Epoch 6/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.8892 - accuracy: 0.1979 - sparse_top_k_categorical_accuracy: 0.3824\n",
            "Epoch 00006: val_accuracy improved from 0.14444 to 0.14756, saving model to /content/drive/My Drive/Models/data_explore/noprep_06.h5\n",
            "1539/1539 [==============================] - 168s 109ms/step - loss: 2.8892 - accuracy: 0.1979 - sparse_top_k_categorical_accuracy: 0.3824 - val_loss: 3.2283 - val_accuracy: 0.1476 - val_sparse_top_k_categorical_accuracy: 0.2825\n",
            "Epoch 7/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.8672 - accuracy: 0.2022 - sparse_top_k_categorical_accuracy: 0.3904\n",
            "Epoch 00007: val_accuracy did not improve from 0.14756\n",
            "1539/1539 [==============================] - 168s 109ms/step - loss: 2.8672 - accuracy: 0.2022 - sparse_top_k_categorical_accuracy: 0.3904 - val_loss: 3.1988 - val_accuracy: 0.1425 - val_sparse_top_k_categorical_accuracy: 0.2854\n",
            "Epoch 8/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.8495 - accuracy: 0.2073 - sparse_top_k_categorical_accuracy: 0.3974\n",
            "Epoch 00008: val_accuracy did not improve from 0.14756\n",
            "1539/1539 [==============================] - 168s 109ms/step - loss: 2.8495 - accuracy: 0.2073 - sparse_top_k_categorical_accuracy: 0.3974 - val_loss: 3.2732 - val_accuracy: 0.1335 - val_sparse_top_k_categorical_accuracy: 0.2842\n",
            "Epoch 9/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.8244 - accuracy: 0.2137 - sparse_top_k_categorical_accuracy: 0.4033\n",
            "Epoch 00009: val_accuracy did not improve from 0.14756\n",
            "1539/1539 [==============================] - 168s 109ms/step - loss: 2.8244 - accuracy: 0.2137 - sparse_top_k_categorical_accuracy: 0.4033 - val_loss: 3.2664 - val_accuracy: 0.1433 - val_sparse_top_k_categorical_accuracy: 0.2918\n",
            "Epoch 10/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.8148 - accuracy: 0.2151 - sparse_top_k_categorical_accuracy: 0.4067\n",
            "Epoch 00010: val_accuracy did not improve from 0.14756\n",
            "1539/1539 [==============================] - 168s 109ms/step - loss: 2.8148 - accuracy: 0.2151 - sparse_top_k_categorical_accuracy: 0.4067 - val_loss: 3.2489 - val_accuracy: 0.1407 - val_sparse_top_k_categorical_accuracy: 0.2922\n",
            "Epoch 11/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.8002 - accuracy: 0.2191 - sparse_top_k_categorical_accuracy: 0.4148\n",
            "Epoch 00011: val_accuracy did not improve from 0.14756\n",
            "1539/1539 [==============================] - 168s 109ms/step - loss: 2.8002 - accuracy: 0.2191 - sparse_top_k_categorical_accuracy: 0.4148 - val_loss: 3.3029 - val_accuracy: 0.1361 - val_sparse_top_k_categorical_accuracy: 0.2828\n",
            "Epoch 12/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.7949 - accuracy: 0.2239 - sparse_top_k_categorical_accuracy: 0.4176\n",
            "Epoch 00012: val_accuracy did not improve from 0.14756\n",
            "1539/1539 [==============================] - 168s 109ms/step - loss: 2.7949 - accuracy: 0.2239 - sparse_top_k_categorical_accuracy: 0.4176 - val_loss: 3.2862 - val_accuracy: 0.1384 - val_sparse_top_k_categorical_accuracy: 0.2875\n",
            "Epoch 13/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.7869 - accuracy: 0.2243 - sparse_top_k_categorical_accuracy: 0.4192\n",
            "Epoch 00013: val_accuracy did not improve from 0.14756\n",
            "1539/1539 [==============================] - 168s 109ms/step - loss: 2.7869 - accuracy: 0.2243 - sparse_top_k_categorical_accuracy: 0.4192 - val_loss: 3.2735 - val_accuracy: 0.1349 - val_sparse_top_k_categorical_accuracy: 0.2782\n",
            "Epoch 14/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.7737 - accuracy: 0.2267 - sparse_top_k_categorical_accuracy: 0.4234\n",
            "Epoch 00014: val_accuracy did not improve from 0.14756\n",
            "1539/1539 [==============================] - 168s 109ms/step - loss: 2.7737 - accuracy: 0.2267 - sparse_top_k_categorical_accuracy: 0.4234 - val_loss: 3.3358 - val_accuracy: 0.1392 - val_sparse_top_k_categorical_accuracy: 0.2865\n",
            "Epoch 15/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.7672 - accuracy: 0.2277 - sparse_top_k_categorical_accuracy: 0.4269\n",
            "Epoch 00015: val_accuracy did not improve from 0.14756\n",
            "1539/1539 [==============================] - 169s 110ms/step - loss: 2.7672 - accuracy: 0.2277 - sparse_top_k_categorical_accuracy: 0.4269 - val_loss: 3.3292 - val_accuracy: 0.1294 - val_sparse_top_k_categorical_accuracy: 0.2743\n",
            "Epoch 16/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.7641 - accuracy: 0.2300 - sparse_top_k_categorical_accuracy: 0.4294\n",
            "Epoch 00016: val_accuracy did not improve from 0.14756\n",
            "1539/1539 [==============================] - 167s 109ms/step - loss: 2.7641 - accuracy: 0.2300 - sparse_top_k_categorical_accuracy: 0.4294 - val_loss: 3.3699 - val_accuracy: 0.1341 - val_sparse_top_k_categorical_accuracy: 0.2741\n",
            "Epoch 17/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.7632 - accuracy: 0.2290 - sparse_top_k_categorical_accuracy: 0.4278\n",
            "Epoch 00017: val_accuracy did not improve from 0.14756\n",
            "1539/1539 [==============================] - 168s 109ms/step - loss: 2.7632 - accuracy: 0.2290 - sparse_top_k_categorical_accuracy: 0.4278 - val_loss: 3.3436 - val_accuracy: 0.1378 - val_sparse_top_k_categorical_accuracy: 0.2817\n",
            "Epoch 18/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.7490 - accuracy: 0.2331 - sparse_top_k_categorical_accuracy: 0.4332\n",
            "Epoch 00018: val_accuracy did not improve from 0.14756\n",
            "1539/1539 [==============================] - 168s 109ms/step - loss: 2.7490 - accuracy: 0.2331 - sparse_top_k_categorical_accuracy: 0.4332 - val_loss: 3.4153 - val_accuracy: 0.1244 - val_sparse_top_k_categorical_accuracy: 0.2719\n",
            "Epoch 19/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.7523 - accuracy: 0.2304 - sparse_top_k_categorical_accuracy: 0.4326\n",
            "Epoch 00019: val_accuracy did not improve from 0.14756\n",
            "1539/1539 [==============================] - 168s 109ms/step - loss: 2.7523 - accuracy: 0.2304 - sparse_top_k_categorical_accuracy: 0.4326 - val_loss: 3.5210 - val_accuracy: 0.1298 - val_sparse_top_k_categorical_accuracy: 0.2659\n",
            "Epoch 20/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.7436 - accuracy: 0.2346 - sparse_top_k_categorical_accuracy: 0.4359\n",
            "Epoch 00020: val_accuracy did not improve from 0.14756\n",
            "1539/1539 [==============================] - 168s 109ms/step - loss: 2.7436 - accuracy: 0.2346 - sparse_top_k_categorical_accuracy: 0.4359 - val_loss: 3.3523 - val_accuracy: 0.1441 - val_sparse_top_k_categorical_accuracy: 0.2867\n",
            "Epoch 21/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.7421 - accuracy: 0.2353 - sparse_top_k_categorical_accuracy: 0.4367\n",
            "Epoch 00021: val_accuracy did not improve from 0.14756\n",
            "1539/1539 [==============================] - 167s 108ms/step - loss: 2.7421 - accuracy: 0.2353 - sparse_top_k_categorical_accuracy: 0.4367 - val_loss: 3.4085 - val_accuracy: 0.1333 - val_sparse_top_k_categorical_accuracy: 0.2733\n",
            "Epoch 00021: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0f15768dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AcYYdSEWTWS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r noprep\n",
        "!rm -r valid_noprep"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwBf2MqqWhc1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cd35d514-5289-4678-e4a0-88a95ee07d56"
      },
      "source": [
        "prep_data_and_model('cropped')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Data details\n",
            "Loading data\n",
            "Prepping model\n",
            "Training model\n",
            "Epoch 1/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 3.2888 - accuracy: 0.1106 - sparse_top_k_categorical_accuracy: 0.2425\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.11404, saving model to /content/drive/My Drive/Models/data_explore/cropped_01.h5\n",
            "1539/1539 [==============================] - 168s 109ms/step - loss: 3.2888 - accuracy: 0.1106 - sparse_top_k_categorical_accuracy: 0.2425 - val_loss: 3.2473 - val_accuracy: 0.1140 - val_sparse_top_k_categorical_accuracy: 0.2626\n",
            "Epoch 2/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 3.1251 - accuracy: 0.1438 - sparse_top_k_categorical_accuracy: 0.2993\n",
            "Epoch 00002: val_accuracy improved from 0.11404 to 0.12027, saving model to /content/drive/My Drive/Models/data_explore/cropped_02.h5\n",
            "1539/1539 [==============================] - 167s 108ms/step - loss: 3.1251 - accuracy: 0.1438 - sparse_top_k_categorical_accuracy: 0.2993 - val_loss: 3.2382 - val_accuracy: 0.1203 - val_sparse_top_k_categorical_accuracy: 0.2682\n",
            "Epoch 3/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 3.0409 - accuracy: 0.1609 - sparse_top_k_categorical_accuracy: 0.3293\n",
            "Epoch 00003: val_accuracy did not improve from 0.12027\n",
            "1539/1539 [==============================] - 166s 108ms/step - loss: 3.0409 - accuracy: 0.1609 - sparse_top_k_categorical_accuracy: 0.3293 - val_loss: 3.2926 - val_accuracy: 0.1177 - val_sparse_top_k_categorical_accuracy: 0.2634\n",
            "Epoch 4/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.9908 - accuracy: 0.1718 - sparse_top_k_categorical_accuracy: 0.3476\n",
            "Epoch 00004: val_accuracy improved from 0.12027 to 0.13567, saving model to /content/drive/My Drive/Models/data_explore/cropped_04.h5\n",
            "1539/1539 [==============================] - 166s 108ms/step - loss: 2.9908 - accuracy: 0.1718 - sparse_top_k_categorical_accuracy: 0.3476 - val_loss: 3.2218 - val_accuracy: 0.1357 - val_sparse_top_k_categorical_accuracy: 0.2782\n",
            "Epoch 5/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.9492 - accuracy: 0.1822 - sparse_top_k_categorical_accuracy: 0.3597\n",
            "Epoch 00005: val_accuracy improved from 0.13567 to 0.14016, saving model to /content/drive/My Drive/Models/data_explore/cropped_05.h5\n",
            "1539/1539 [==============================] - 167s 109ms/step - loss: 2.9492 - accuracy: 0.1822 - sparse_top_k_categorical_accuracy: 0.3597 - val_loss: 3.2095 - val_accuracy: 0.1402 - val_sparse_top_k_categorical_accuracy: 0.2778\n",
            "Epoch 6/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.9204 - accuracy: 0.1878 - sparse_top_k_categorical_accuracy: 0.3724\n",
            "Epoch 00006: val_accuracy did not improve from 0.14016\n",
            "1539/1539 [==============================] - 166s 108ms/step - loss: 2.9204 - accuracy: 0.1878 - sparse_top_k_categorical_accuracy: 0.3724 - val_loss: 3.4887 - val_accuracy: 0.1378 - val_sparse_top_k_categorical_accuracy: 0.2612\n",
            "Epoch 7/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.9035 - accuracy: 0.1927 - sparse_top_k_categorical_accuracy: 0.3773\n",
            "Epoch 00007: val_accuracy did not improve from 0.14016\n",
            "1539/1539 [==============================] - 167s 108ms/step - loss: 2.9035 - accuracy: 0.1927 - sparse_top_k_categorical_accuracy: 0.3773 - val_loss: 3.3220 - val_accuracy: 0.1209 - val_sparse_top_k_categorical_accuracy: 0.2657\n",
            "Epoch 8/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.8821 - accuracy: 0.1993 - sparse_top_k_categorical_accuracy: 0.3875\n",
            "Epoch 00008: val_accuracy did not improve from 0.14016\n",
            "1539/1539 [==============================] - 167s 108ms/step - loss: 2.8821 - accuracy: 0.1993 - sparse_top_k_categorical_accuracy: 0.3875 - val_loss: 3.2538 - val_accuracy: 0.1310 - val_sparse_top_k_categorical_accuracy: 0.2788\n",
            "Epoch 9/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.8595 - accuracy: 0.2026 - sparse_top_k_categorical_accuracy: 0.3934\n",
            "Epoch 00009: val_accuracy did not improve from 0.14016\n",
            "1539/1539 [==============================] - 166s 108ms/step - loss: 2.8595 - accuracy: 0.2026 - sparse_top_k_categorical_accuracy: 0.3934 - val_loss: 3.2954 - val_accuracy: 0.1269 - val_sparse_top_k_categorical_accuracy: 0.2782\n",
            "Epoch 10/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.8469 - accuracy: 0.2062 - sparse_top_k_categorical_accuracy: 0.3983\n",
            "Epoch 00010: val_accuracy did not improve from 0.14016\n",
            "1539/1539 [==============================] - 166s 108ms/step - loss: 2.8469 - accuracy: 0.2062 - sparse_top_k_categorical_accuracy: 0.3983 - val_loss: 3.3983 - val_accuracy: 0.1333 - val_sparse_top_k_categorical_accuracy: 0.2665\n",
            "Epoch 11/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.8404 - accuracy: 0.2086 - sparse_top_k_categorical_accuracy: 0.3995\n",
            "Epoch 00011: val_accuracy did not improve from 0.14016\n",
            "1539/1539 [==============================] - 167s 108ms/step - loss: 2.8404 - accuracy: 0.2086 - sparse_top_k_categorical_accuracy: 0.3995 - val_loss: 3.3065 - val_accuracy: 0.1384 - val_sparse_top_k_categorical_accuracy: 0.2745\n",
            "Epoch 12/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.8312 - accuracy: 0.2127 - sparse_top_k_categorical_accuracy: 0.4055\n",
            "Epoch 00012: val_accuracy did not improve from 0.14016\n",
            "1539/1539 [==============================] - 166s 108ms/step - loss: 2.8312 - accuracy: 0.2127 - sparse_top_k_categorical_accuracy: 0.4055 - val_loss: 3.3194 - val_accuracy: 0.1365 - val_sparse_top_k_categorical_accuracy: 0.2789\n",
            "Epoch 13/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.8154 - accuracy: 0.2126 - sparse_top_k_categorical_accuracy: 0.4098\n",
            "Epoch 00013: val_accuracy did not improve from 0.14016\n",
            "1539/1539 [==============================] - 165s 107ms/step - loss: 2.8154 - accuracy: 0.2126 - sparse_top_k_categorical_accuracy: 0.4098 - val_loss: 3.3770 - val_accuracy: 0.1298 - val_sparse_top_k_categorical_accuracy: 0.2723\n",
            "Epoch 14/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.8063 - accuracy: 0.2167 - sparse_top_k_categorical_accuracy: 0.4105\n",
            "Epoch 00014: val_accuracy did not improve from 0.14016\n",
            "1539/1539 [==============================] - 166s 108ms/step - loss: 2.8063 - accuracy: 0.2167 - sparse_top_k_categorical_accuracy: 0.4105 - val_loss: 3.3561 - val_accuracy: 0.1298 - val_sparse_top_k_categorical_accuracy: 0.2690\n",
            "Epoch 15/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.8038 - accuracy: 0.2180 - sparse_top_k_categorical_accuracy: 0.4129\n",
            "Epoch 00015: val_accuracy did not improve from 0.14016\n",
            "1539/1539 [==============================] - 166s 108ms/step - loss: 2.8038 - accuracy: 0.2180 - sparse_top_k_categorical_accuracy: 0.4129 - val_loss: 3.3573 - val_accuracy: 0.1329 - val_sparse_top_k_categorical_accuracy: 0.2739\n",
            "Epoch 16/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.8011 - accuracy: 0.2171 - sparse_top_k_categorical_accuracy: 0.4145\n",
            "Epoch 00016: val_accuracy did not improve from 0.14016\n",
            "1539/1539 [==============================] - 166s 108ms/step - loss: 2.8011 - accuracy: 0.2171 - sparse_top_k_categorical_accuracy: 0.4145 - val_loss: 3.3640 - val_accuracy: 0.1285 - val_sparse_top_k_categorical_accuracy: 0.2686\n",
            "Epoch 17/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.7909 - accuracy: 0.2199 - sparse_top_k_categorical_accuracy: 0.4175\n",
            "Epoch 00017: val_accuracy did not improve from 0.14016\n",
            "1539/1539 [==============================] - 166s 108ms/step - loss: 2.7909 - accuracy: 0.2199 - sparse_top_k_categorical_accuracy: 0.4175 - val_loss: 3.4274 - val_accuracy: 0.1306 - val_sparse_top_k_categorical_accuracy: 0.2688\n",
            "Epoch 18/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.7874 - accuracy: 0.2211 - sparse_top_k_categorical_accuracy: 0.4191\n",
            "Epoch 00018: val_accuracy did not improve from 0.14016\n",
            "1539/1539 [==============================] - 165s 107ms/step - loss: 2.7874 - accuracy: 0.2211 - sparse_top_k_categorical_accuracy: 0.4191 - val_loss: 3.3643 - val_accuracy: 0.1288 - val_sparse_top_k_categorical_accuracy: 0.2756\n",
            "Epoch 19/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.7872 - accuracy: 0.2230 - sparse_top_k_categorical_accuracy: 0.4218\n",
            "Epoch 00019: val_accuracy did not improve from 0.14016\n",
            "1539/1539 [==============================] - 166s 108ms/step - loss: 2.7872 - accuracy: 0.2230 - sparse_top_k_categorical_accuracy: 0.4218 - val_loss: 3.4465 - val_accuracy: 0.1320 - val_sparse_top_k_categorical_accuracy: 0.2635\n",
            "Epoch 20/30\n",
            "1539/1539 [==============================] - ETA: 0s - loss: 2.7842 - accuracy: 0.2229 - sparse_top_k_categorical_accuracy: 0.4229\n",
            "Epoch 00020: val_accuracy did not improve from 0.14016\n",
            "1539/1539 [==============================] - 166s 108ms/step - loss: 2.7842 - accuracy: 0.2229 - sparse_top_k_categorical_accuracy: 0.4229 - val_loss: 3.3987 - val_accuracy: 0.1216 - val_sparse_top_k_categorical_accuracy: 0.2618\n",
            "Epoch 00020: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0f128730b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owSV1Tv1xwlG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r cropped\n",
        "!rm -r valid_cropped"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8FQY-QYcD_k",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate Models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGdeDcc3d-t4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_data_pred(dataset, skip_load = False):\n",
        "    print('Loading Data details')\n",
        "    # Prep datasets\n",
        "    with open('/content/drive/My Drive/Data/final-book30-labels-test.csv', mode='r', encoding='utf-8', errors='ignore') as f:\n",
        "        test_labels = pd.read_csv(f, delimiter=\",\", header=None, names=['record', 'Filename', 'Category ID'])\n",
        "\n",
        "    test_labels = test_labels.assign(Full_Filename = f'/content/test_{dataset}/{dataset}/'+ test_labels[\"Filename\"])\n",
        "\n",
        "    print('Loading data')\n",
        "    if not skip_load:\n",
        "        # Load actual data\n",
        "\n",
        "        zip_path = f'/content/drive/My Drive/images/Test/{dataset}.zip'\n",
        "        !cp \"{zip_path}\" .\n",
        "        !unzip -q \"{dataset}.zip\"  -d \"test_{dataset}\" \n",
        "        !rm \"{dataset}.zip\" \n",
        "\n",
        "    my_test_batch_generator = My_Custom_Generator(test_labels[\"Full_Filename\"], test_labels[\"Category ID\"], BATCH_SIZE, IMG_HEIGHT, IMG_WIDTH)\n",
        "    print('Loading model')\n",
        "\n",
        "    base_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3),\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n",
        "\n",
        "    base_model.trainable = False\n",
        "\n",
        "    model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(30, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='Adam',\n",
        "              loss='SparseCategoricalCrossentropy',\n",
        "              metrics=['accuracy', tf.keras.metrics.SparseTopKCategoricalAccuracy(3)])\n",
        "    \n",
        "    files = os.listdir('/content/drive/My Drive/Models/data_explore/')\n",
        "    pat = re.compile(f'^.*{dataset}.*\\.h5$')\n",
        "    files_cut = [i for i in files if pat.match(i) ]\n",
        "    model_weights = max(files_cut)\n",
        "\n",
        "    model.load_weights(f'/content/drive/My Drive/Models/data_explore/{model_weights}')\n",
        "\n",
        "    print('Making predition')\n",
        "\n",
        "    y_pred = np.argmax(model.predict(my_test_batch_generator, steps = int(len(test_labels) // BATCH_SIZE)), axis=-1)\n",
        "\n",
        "\n",
        "    return y_pred, test_labels[\"Category ID\"]\n",
        "\n",
        "\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pOo6h9RgnTS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "7abb2a6d-44e3-41e0-a35d-eb12ba2d67e0"
      },
      "source": [
        "padded_pred, y_true = test_data_pred('padded')\n",
        "!rm -r test_padded\n",
        "noprep_pred, y_true = test_data_pred('noprep')\n",
        "!rm -r test_noprep\n",
        "cropped_pred, y_true = test_data_pred('cropped')\n",
        "!rm -r test_cropped"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Data details\n",
            "Loading data\n",
            "Loading model\n",
            "Making predition\n",
            "Loading Data details\n",
            "Loading data\n",
            "Loading model\n",
            "Making predition\n",
            "Loading Data details\n",
            "Loading data\n",
            "Loading model\n",
            "Making predition\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZM2pWMNYh7IJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f441176d-678f-4601-d8b1-a652333ed78c"
      },
      "source": [
        "# best method based on overall top 1 accuracy is padded.\n",
        "print('Padded: ', accuracy_score(padded_pred, y_true), '\\n',\n",
        "      'NoPrep: ',accuracy_score(noprep_pred, y_true), '\\n',\n",
        "      'Cropped: ',accuracy_score(cropped_pred, y_true), sep = '')\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Padded: 0.1580701754385965\n",
            "NoPrep: 0.14385964912280702\n",
            "Cropped: 0.1287719298245614\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}